{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from getpass import getpass\n",
    "from textworld_express import TextWorldExpressEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an API client\n",
    "The cell creates a client for OpenAI's API, and it will ask for a key to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = getpass('OpenAI API key:')\n",
    "\n",
    "open_ai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_openai(model, messages):\n",
    "  ### The following code is inspired by OpenAI's API docs ###\n",
    "  completion = open_ai_client.chat.completions.create(\n",
    "      model = model, messages = messages)\n",
    "  return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the prompts\n",
    "\n",
    "The function react_1 builds a prompt where think and act steps are combined within a single prompt. The LLM is asked to think and then select the most appropriate action from the list of available actions.\n",
    "\n",
    "The function react_2 builds a prompt where think and act steps are divided into two different prompts. The LLM is first asked to think about the best ways to achieve the task based on what it has observed from the environment. Then, in a second prompt, the model is asked to select the action.\n",
    "\n",
    "In both cases the LLM has access to a limited context (5 most recent interactions, including both prompts and the reasoning traces)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_agent(model, task, obs, valid_actions):\n",
    "    return random.choice(valid_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_prompt(model, task, obs, valid_actions): \n",
    "    global messages \n",
    "    if not len(messages):\n",
    "        messages.append({\"role\": \"system\", \"content\": f'You are in the middle of a game that checks common sense. \\\n",
    "Your objective in this game is the following: {task}'})\n",
    "    messages.append({\"role\": \"user\", \"content\": f'{obs} Now, given your objective, think how you could achieve it and \\\n",
    "what steps you could take. Remember: there may be multiple locations, \\\n",
    "and you want to avoid repeating things again and again. Now, taking into account \\\n",
    "your thoughts, choose one most reasonable action out of these: {valid_actions}. \\\n",
    "The action has to be in the list and you must respond with the action only, using the same spelling.'})\n",
    "    messages.append({\"role\": \"assistant\", \"content\": f'{ask_openai(model, messages)}'})\n",
    "    messages = [messages[0]] + messages[1:][-11:]\n",
    "    return messages[-1][\"content\"].replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def react_1(model, task, obs, valid_actions): \n",
    "    global messages \n",
    "    if not len(messages):\n",
    "        messages.append({\"role\": \"system\", \"content\": f'You are in the middle of a game that checks common sense. \\\n",
    "Your objective in this game is the following: {task}'})\n",
    "    messages.append({\"role\": \"user\", \"content\": f'{obs} Now, given your objective, think how you could achieve it and \\\n",
    "what steps you could take. Be concise when reasoning, and after generating\\\n",
    "your thoughts, choose one most reasonable action out of these: {valid_actions}. \\\n",
    "The action has to be in the list and you must place the action with # on each side after your thoughts.'})\n",
    "    messages.append({\"role\": \"assistant\", \"content\": f'{ask_openai(model, messages)}'})\n",
    "    messages = [messages[0]] + messages[1:][-11:]\n",
    "    return messages[-1][\"content\"].replace(\"'\", \"\").split('#')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def react_2(model, task, obs, valid_actions): \n",
    "    global messages \n",
    "    if not len(messages):\n",
    "        messages.append({\"role\": \"system\", \"content\": f'You are in the middle of a game that checks common sense. \\\n",
    "Your objective in this game is the following: {task}'})\n",
    "    messages.append({\"role\": \"user\", \"content\": f'{obs} Now, given your objective, think how you could achieve it and \\\n",
    "what steps you could take. Do not take any action yet, just think. Be concise.'})\n",
    "    messages.append({\"role\": \"assistant\", \"content\": f'{ask_openai(model, messages)}'})\n",
    "    messages.append({\"role\": \"user\", \"content\": f'Remember: there may be multiple locations, \\\n",
    "and if you see that you are going in circles, do not do the same thing again. Now, taking into account \\\n",
    "your previous thoughts, choose one most reasonable action out of these: {valid_actions}. \\\n",
    "The action has to be in the list and you must respond with the action only, using the same spelling.'})\n",
    "    messages.append({\"role\": \"assistant\", \"content\": f'{ask_openai(model, messages)}'})\n",
    "    messages = [messages[0]] + messages[1:][-21:]\n",
    "    return messages[-1][\"content\"].replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the simulation environment\n",
    "\n",
    "The simulation environment code below uses the TextWorldExpress library. As a consequence, a lot of code is the result of adaptation from the original code by TextWorldExpress authors.\n",
    "\n",
    "The play() takes one of the OpenAI model names as the argument, the react agent as the second, episode range and number of steps as the third, and if the export flag is set to True, it will write the results of the simulation as a .csv file to the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The code in this cell borrows from the TextWorldExpress Github repository on multiple occasions###\n",
    "def play(model, react_func, n_episodes=(0, 50), n_steps=50, export=False):\n",
    "  global messages\n",
    "  env = TextWorldExpressEnv(envStepLimit=n_steps)\n",
    "  # Set the game generator to generate a particular game (cookingworld, twc, or coin)\n",
    "  env.load(gameName=\"twc\", gameParams='') #gameParams=f'numLocations={random.randint(1, 2)},\\\n",
    "                                        #includeDoors=1, numItemsToPutAway={random.randint(3,4)}')\n",
    "\n",
    "  # Then, randomly generate and play 10 games within the defined parameters\n",
    "  episode_data = []\n",
    "  for episode_id in range(n_episodes[0], n_episodes[1]):\n",
    "    # First step\n",
    "    obs, infos = env.reset(seed=episode_id, gameFold=\"train\", generateGoldPath=True)\n",
    "    task = infos['taskDescription']\n",
    "\n",
    "    for step_id in range(n_steps):\n",
    "      # Select a random valid action\n",
    "      validActions = sorted(infos['validActions'])\n",
    "      llm_action = react_func(model, task, obs, validActions)\n",
    "\n",
    "      # Take that action\n",
    "      obs, reward, done, infos = env.step(llm_action)\n",
    "\n",
    "      # Display action and the game's feedback.\n",
    "      print(\">\", llm_action)\n",
    "      print(obs)\n",
    "      print(infos['score'], infos['numMoves'])\n",
    "\n",
    "      if infos['tasksuccess']:\n",
    "          print(\"Task Success!\")\n",
    "      if infos['taskfailure']:\n",
    "          print(\"Task Failure!\")\n",
    "      if infos['done'] or step_id == n_steps-1:\n",
    "        episode_data.append([episode_id, infos['score'], infos['numMoves'], infos['done']])\n",
    "        break\n",
    "    messages = [] \n",
    "  if export:\n",
    "     episode_data = pd.DataFrame(episode_data, columns=['episode_id', 'score', 'num_moves', 'done'])\n",
    "     episode_data.to_csv(f'data/{model}_{react_func.__name__}_{n_episodes}episodes_{n_steps}steps_{str(time.time())[:10]}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data\n",
    "\n",
    "Finally, the cell below will simulate 50 episodes of the TextWorldExpress Commonsense game for each of the agents we have built. The maximum number of steps per episode will be capped at 50. Then it will save the run data as two separate .csv files into the /data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "play('gpt-4o-mini', random_agent, export=True)\n",
    "play('gpt-4o-mini', basic_prompt, export=True)\n",
    "play('gpt-4o-mini', react_1, export=True)\n",
    "play('gpt-4o-mini', react_2, export=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
